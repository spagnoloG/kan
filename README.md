# ğŸŒŸ Understanding Kolmogorov-Arnold Networks (KANs)

## ğŸ“ Summary: Introduction to Kolmogorov-Arnold Networks
This repository provides foundational knowledge for understanding **Kolmogorov-Arnold Networks (KANs)**, starting with BÃ©zier curves, B-splines, and their role in function approximation. Building on these concepts, it explains the KAN architecture and its applications in approximating complex functions.

## ğŸ¯ Lecture Overview
In this lecture, we will cover the following topics:

### 1. [**ğŸ¨ BÃ©zier Curves**](https://github.com/spagnoloG/kan/blob/main/code/notebooks/01-bezier_curves.ipynb)
   - Introduction to BÃ©zier curves.
   - Mathematical formulation and significance in curve modeling.
   - Visualization and examples.

### 2. [**ğŸ“ B-splines**](https://github.com/spagnoloG/kan/blob/main/code/notebooks/02-bsplines.ipynb)
   - Overview of B-splines and their properties.
   - Role of linear combinations in function approximation.
   - Practical applications of B-splines in modeling.

### 3. [**ğŸ”§ Function Approximation with Splines**](https://github.com/spagnoloG/kan/blob/main/code/notebooks/02-bsplines.ipynb)
   - Understanding spline-based function approximation.
   - Comparing splines with other function approximation methods.
   - Challenges and advantages.

### 4. [**ğŸš€ Kolmogorov-Arnold Networks (KANs)**](https://github.com/spagnoloG/kan/blob/main/code/notebooks/03-kan.ipynb)
   - Introduction to the KAN architecture.
   - Theoretical foundations:
     - Kolmogorov-Arnold representation theorem.
     - Splines as building blocks in KANs.
   - Applications of KANs in machine learning and function approximation.
   - Benefits and limitations of KANs.

## ğŸ“š Resources
To supplement the lecture, explore these resources:

### **KAN Resources**
- ğŸ“„ [KAN: Kolmogorovâ€“Arnold Networks (Paper)](https://arxiv.org/pdf/2404.19756)
- ğŸŒ [Beginner-friendly Introduction to KAN](https://www.dailydoseofds.com/a-beginner-friendly-introduction-to-kolmogorov-arnold-networks-kan/)
- ğŸ› ï¸ [From-Scratch Implementation of KANs](https://mlwithouttears.com/2024/05/15/a-from-scratch-implementation-of-kolmogorov-arnold-networks-kan/)
- ğŸ—‚ï¸ [GitHub: Code for KAN Implementation](https://github.com/lollodealma/ml_without_tears/tree/master)
- ğŸ“˜ [KAN Tutorial Notebooks](https://github.com/pg2455/KAN-Tutorial/tree/main)
- ğŸ¥ [Video: Kolmogorov-Arnold Networks Explained](https://www.youtube.com/watch?v=-PFIkkwWdnM)

### **MLP (Multilayer Perceptron) Resources**
- ğŸ“º [Video Series by Andrej Karpathy](https://www.youtube.com/watch?v=VMj-3S1tku0&list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&index=1)
- ğŸ§  [How to Code a Neural Network with Backpropagation in Python](https://machinelearningmastery.com/implement-backpropagation-algorithm-scratch-python/)
- ğŸ–Šï¸ [MNIST From-Scratch Neural Network](https://github.com/t9nzin/mnist-from-scratch/blob/main/src/neural_network.py)
- ğŸ“– [Backpropagation and Gradient Descent Simplified](https://www.pycodemates.com/2023/02/backpropagation-and-gradient-descent-simplified.html)
- ğŸ”¨ [Building a Neural Network From Scratch](https://www.pycodemates.com/2023/04/coding-a-neural-network-from-scratch-using-python.html)

For any issues or contributions, feel free to open an issue or submit a pull request. ğŸ¤